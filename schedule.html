<head>
</head>


<body bgcolor="#ffffff" topmargin="0" leftmargin="0" marginheight="0" marginwidth="0">


<table border="0" cellpadding="0" cellspacing="0" align="right">
<tr>
<td><!--***************************************************************************************-->
<A onmouseover="window.status&#13;&#10;='Main Page';
 return true"
 onmouseout ="window.status=''; return true" href="./index.html" >
Main Page</A>&nbsp;&nbsp;<font color="#660099">|</font>&nbsp;&nbsp; <!--***************************************************************************************-->

</td>

<td><!--***************************************************************************************-->
<A onmouseover="window.status&#13;&#10;='Schedule';
 return true"
 onmouseout ="window.status=''; return true" href="./schedule.html" >
Schedule</A>&nbsp;&nbsp;<font color="#660099">|</font>&nbsp;&nbsp; <!--***************************************************************************************-->
</td>



</tr>
</table>

<table border="0" cellpadding="0" cellspacing="0" width="436">

<tr>
<td width="60" valign="top"><!--***************************************************************************************-->&nbsp; 
<!--***************************************************************************************-->
</td>
<td><!--***************************************************************************************-->
<!--<a href="http://www.manchester.ac.uk/"
 onMouseOver 
="window.status='image1'; return true"
 onMouseOut="window.status=''; return true" 
      align="right" valign  ="top" 
     ; <P 
     ><IMG alt="University Logo" title="Manchester Est. 1824" src="http://www.cs.manchester.ac.uk/ai/pictures/icons/est1824.gif"> -->
<!--***************************************************************************************-->
</td>
</tr>
</table></body>

<div class="section"><head><title>Conference Schedule</title></head>
<h1>Statistics and Machine Learning Interface Meeting</h1><h2>Workshop Schedule</h2>

<table width="100%">
  <tr>
    <td width="10%" ><a name="registration"></a>10:00 - 10:15</td>
    <td width="90%"><b>Registration for the Workshop</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="welcome"></a>10:15 - 10:25</td>
    <td width="90%"><b>Welcome and Introduction</b>
[<a href="./slides/introduction.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~neill">Neil Lawrence</a></td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="wackernagel"></a>10:25 - 11:05</td>
    <td width="90%"><b>Geostatistical model, covariance structure and cokriging</b>
[<a href="./slides/wackernagel.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://hans.wackernagel.free.fr/">Hans Wackernagel</a>, <i>Mines, Paris Tech</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Kriging has been introduced as a statistical interpolation method for
the design of computer experiments some twenty years ago.  However,
many aspects of the geostatistical methodology originally developed
for natural resource estimation have been ignored when switching to
this new context.  This talk reviews concepts of multivariate
geostatistics and in particular the estimation of components of
spatial variation in the context of multiple correlated outputs.
Application examples to ocean model output and remote sensing
sea-surface temperature data are discussed.

</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion1"></a>11:05 - 11:25</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="coffee1"></a>11:25 - 11:45</td>
    <td width="90%"><b>Coffee Break</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="ohagan"></a>11:45 - 12:25</td>
    <td width="90%"><b>Gaussian process emulation of multiple outputs</b>
[<a href="./slides/ohagan.pptx">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.tonyohagan.co.uk/academic/">Tony O'Hagan</a>, <i>Department of Probability and Statistics, University of Sheffield</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    The use of GPs to model the outputs of complex simulators is well 
established.  The GP trained on a sample of simulator outputs is known as 
an emulator, and allows tasks such as uncertainty analysis and calibration to 
be done with a minimum of expensive simulator runs.  Simulators typically 
produce many outputs, or even whole time series or spatial fields of outputs, 
and the challenge then is to find effective ways to emulate multiple outputs.

I will review the various emulation strategies that have been suggested, 
drawing connections between them and discussing the situations under 
which alternative methods would be appropriate.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion2"></a>12:25 - 12:45</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="lunch1"></a>12:45 - 14:15</td>
    <td width="90%"><b>Lunch</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="alvarez"></a>14:15 - 14:55</td>
    <td width="90%"><b>Efficient Sparse Approximations for Convolution Processes</b>
[<a href="./slides/alvarez.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~alvarezm/">Mauricio Alvarez</a>, <i>School of Computer Science, University of Manchester</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    One approach to account for non-trivial correlations between outputs
employs convolution processes. Under a latent function interpretation
of the convolution transform it is possible to establish dependencies
between output variables. However, efficient inference for this
approach is usually a critical point. We present different sparse
approximations for dependent output Gaussian processes constructed
through the convolution formalism. Basically, we exploit the
conditional independencies present naturally in the model leading to
forms of the covariance similar in spirit to the PITC approximation
and FITC approximations for a single output.  We also present another
set of variational approximations that provide a rigorous lower bound
for the marginal likelihood of the model and introduce the concepts of
variational inducing functions and variational inducing kernels to
allow the latent functions to be white noise processes.

Joint work with Neil Lawrence, David Luengo and Michalis Titsias. 
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion3"></a>14:55 - 15:15</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="williams"></a>15:15 - 15:55</td>
    <td width="90%"><b>What should be transferred in transfer learning?</b>
[<a href="./slides/williams.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.dai.ed.ac.uk/homes/ckiw/">Chris Williams</a>, <i>School of Informatics, University of Edinburgh</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    I will start by discussing multi-task learning, and a number of ways
in which transfer between tasks can take place, mainly in a co-kriging
(or Gaussian process) framework. If there is time I will go into more
detail on Multi-task Gaussian Process Learning of Robot Inverse
Dynamics (joint work with Kian Ming Chai, Stefan Klanke, Sethu
Vijayakumar).
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion4"></a>15:55 - 16:15</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="tea1"></a>16:15 - 16:35</td>
    <td width="90%"><b>Tea Break</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="lawrence"></a>16:35 - 17:15</td>
    <td width="90%"><b>Latent Force Models and Multiple Output Gaussian Processes</b>
[<a href="./slides/lawrence.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~neill">Neil D. Lawrence</a>, <i>School of Computer Science, University of Manchester</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    We are used to dealing with the situation where we have a latent
variable. Often we assume this latent variable to be independently
drawn from a distribution, e.g. probabilistic PCA or factor
analysis. This simplification is often extended for temporal data
where tractable Markovian independence assumptions are used
(e.g. Kalman filters or hidden Markov models). In this talk we will
consider the more general case where the latent variable is a forcing
function in a differential equation model. We will show how for
some simple ordinary differential equations the latent variable can be
dealt with analytically for particular Gaussian process priors over
the latent force. In this talk we will introduce the general
framework and present results in systems biology and motion capture.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion6"></a>17:15 - 17:35</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="dinner"></a>19:00 - 21:00</td>
    <td width="90%"><b>Workshop Dinner</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://new.samsi.co.uk/">New Samsi Restaurant</a></td>
  </tr>
</table><h3>Friday 24  July</h3>

<table width="100%">
  <tr>
    <td width="10%" ><a name="cornford"></a>10:00 - 10:40</td>
    <td width="90%"><b>Using prior knowledge in dynamic settings for multivariate Gaussian processes</b>
[<a href="./slides/cornford.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www1.aston.ac.uk/eas/staff-list/dr-dan-cornford/">Dan Cornford</a>, <i>Computer Science, Aston University</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    In this talk I will review the basic methods that physical scientists have been using for many years to work with huge, uncertain multivariate systems. I'll try and provide a context, starting with early work on constructing balanced fields in weather prediction models, move on to more modern dynamic methods based on 'ensembles' (which I will define) and finally briefly present some of our recent work on variational approaches to inference in stochastic dynamic models and show how this relates to the earlier works. I will try and suggest what I think the big open issues are, and how these might be addressed.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion5"></a>10:40 - 11:00</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="coffee2"></a>11:00 - 11:20</td>
    <td width="90%"><b>Coffee Break</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="vernon"></a>11:20 - 12:00</td>
    <td width="90%"><b>Bayes Linear Emulation of Computer Models</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://maths.dur.ac.uk/php/members.php?pattern=dma6irv&parent_page=people">Ian Vernon</a>, <i>Department of Mathematical Sciences, University of Durham</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    I will introduce Bayes Linear Methodology, where expectation as opposed to probability is viewed as primitive. In this approach Bayes Theorem is replaced by the corresponding Bayes Linear Update for expectations, and we require prior specification of only expectations, variances and covariances of all quantities of interest. I will discuss how this can be applied naturally to the process of emulating computer model output, and describe an application involving the  calibration of a Galaxy Formation simulation.


</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion8"></a>12:00 - 12:20</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="lunch2"></a>12:20 - 13:20</td>
    <td width="90%"><b>Lunch</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="wilkinson"></a>13:20 - 14:00</td>
    <td width="90%"><b>Calibrating the UVic climate model using principal component emulation</b>
[<a href="./slides/wilkinson.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://r-d-wilkinson.staff.shef.ac.uk/">Richard Wilkinson</a>, <i>Department of Probability and Statistics, University of Sheffield</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    Uncertainties about potential feedbacks in the terrestrial carbon cycle
are a key driver of the uncertainty in carbon cycle and climate
projections. Here we analyze how oceanic, atmospheric and ice core
carbon cycle observations improve key biogeochemical parameter
estimates. We emulate the output of the UVic climate model using
principal component analysis to reduce the dimension of the output
before using Gaussian processes to model the reduced dimension model. We
then reconstruct to the full space in order to calibrate the model,
carefully accounting for code uncertainty as well as measurement, model
and reconstruction error.

Joint work with Nathan Urban
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion9"></a>14:00 - 14:20</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="fricker"></a>14:20 - 15:00</td>
    <td width="90%"><b>Multivariate Emulation: Is it Worth the Trouble?</b>
[<a href="./slides/fricker.pdf">slides</a>]
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.pas-postgrads.group.shef.ac.uk/fricker/">Tom Fricker</a>, <i>Department of Probability and Statistics, University of Sheffield</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    An emulator is a statistical surrogate for an expensive computer model, used to
obtain fast probabilistic predictions of the outputs. Gaussian processes are
frequently used for this purpose. Typically the data used to train the emulator
is isotopic: values for all outputs are available at all sampling points. In
this scenario, independent univariate GP emulators often produce predictions of
individual outputs that are at least as good as a multivariate GP emulator, and
avoid the difficulty of specifying the cross-covariance structure. This begs
the question: why bother with a multivariate specification?

I this talk I shall present examples where, while independent emulators are
indeed the best option if interest is only in the marginal predictions of
individual outputs, important information is lost when we consider what the
model-user wishes to actually do with the outputs. Then the multivariate
specification becomes necessary, and I shall compare some different options
that are available for the covariance structure.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion10"></a>15:00 - 15:20</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="tea2"></a>15:20 - 15:40</td>
    <td width="90%"><b>Tea Break</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="chai"></a>15:40 - 16:20</td>
    <td width="90%"><b>Generalization Errors and Learning Curves for Regression with Multi-task Gaussian Processes</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://homepages.inf.ed.ac.uk/s9810791/">Kian Ming Chai</a>, <i>School of Informatics, University of Edinburgh, U.K.</i></td>
  </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    I will discuss how task correlations in multi-task Gaussian process
(GP) regression affect the generalization error and the learning
curve, concentrating on the asymmetric two-task case.  Lower and upper
bounds to the generalization error and the learning curve will be
given.
</td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="discussion11"></a>16:20 - 16:40</td>
    <td width="90%"><b>Discussion</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    </td>
  </tr>
</table>
<table width="100%">
  <tr>
    <td width="10%" ><a name="closing"></a>16:40 - 16:45</td>
    <td width="90%"><b>Closing Comments</b>
 </td>
 </tr>

  <tr>
    <td width="10%" >&nbsp;</td>
    <td width="90%" >
    <a href="http://www.cs.man.ac.uk/~neill">Neil Lawrence</a></td>
  </tr>
</table><p align="center">Page last updated on Wednesday 26 Aug 2009 at 09:24</p></div><!-- footer -->

<body>
    <div id="footer">
      <div class="links">
      </div>
      <div class="pagestatus">
        <p>Please contact
          <a href="mailto:alvarezm@cs.man.ac.uk">alvarezm@cs.man.ac.uk</a>
          with comments and suggestions
        </p>
      </div>
    </div>

  </body>
